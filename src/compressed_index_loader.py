#!/usr/bin/env python3
"""
å‹ç¼©è¯­ä¹‰ç´¢å¼•åŠ è½½å™¨
æ”¯æŒä»å‹ç¼©æ–‡ä»¶è‡ªåŠ¨è§£å‹åŠ è½½
"""

import json
import gzip
import numpy as np
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


def load_compressed_index(data_dir: Path):
    """
    åŠ è½½å‹ç¼©çš„è¯­ä¹‰ç´¢å¼•
    
    ä¼˜å…ˆé¡ºåºï¼š
    1. å°è¯•åŠ è½½å·²è§£å‹çš„åŸå§‹æ–‡ä»¶
    2. å°è¯•åŠ è½½å‹ç¼©æ–‡ä»¶ï¼ˆè‡ªåŠ¨è§£å‹ï¼‰
    
    Returns:
        (embeddings, paragraphs, metadata) æˆ– None
    """
    index_dir = data_dir / "zhipu_index"
    
    # æ–¹æ¡ˆ1: æ£€æŸ¥æ˜¯å¦å·²æœ‰è§£å‹åçš„æ–‡ä»¶
    if (index_dir / "embeddings.npy").exists() and (index_dir / "metadata.json").exists():
        logger.info("ğŸ“‚ å‘ç°å·²è§£å‹çš„ç´¢å¼•æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½")
        try:
            embeddings = np.load(index_dir / "embeddings.npy")
            with open(index_dir / "metadata.json", 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            return embeddings, metadata['paragraphs'], metadata['metadata']
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½å·²è§£å‹æ–‡ä»¶å¤±è´¥: {e}")
    
    # æ–¹æ¡ˆ2: åŠ è½½å‹ç¼©æ–‡ä»¶
    compressed_dir = data_dir
    emb_file = compressed_dir / "zhipu_index_embeddings.npz"
    texts_file = compressed_dir / "zhipu_index_texts.json.gz"
    meta_file = compressed_dir / "zhipu_index_meta.json.gz"
    
    if not emb_file.exists():
        logger.error(f"âŒ æ‰¾ä¸åˆ°å‹ç¼©ç´¢å¼•æ–‡ä»¶: {emb_file}")
        return None
    
    logger.info("ğŸ“¦ åŠ è½½å‹ç¼©ç´¢å¼•æ–‡ä»¶...")
    
    try:
        # åŠ è½½ embeddings
        logger.info("  ğŸ“Š åŠ è½½ embeddings...")
        with np.load(emb_file) as data:
            embeddings = data['embeddings']
        logger.info(f"  âœ… embeddings: {embeddings.shape}")
        
        # åŠ è½½ paragraphs
        logger.info("  ğŸ“ åŠ è½½ paragraphs...")
        if texts_file.exists():
            with gzip.open(texts_file, 'rt', encoding='utf-8') as f:
                paragraphs = json.load(f)
        else:
            paragraphs = []
            logger.warning("âš ï¸ æ‰¾ä¸åˆ° texts æ–‡ä»¶ï¼Œparagraphs ä¸ºç©º")
        
        # åŠ è½½ metadata
        logger.info("  ğŸ“‹ åŠ è½½ metadata...")
        if meta_file.exists():
            with gzip.open(meta_file, 'rt', encoding='utf-8') as f:
                metadata_list = json.load(f)
        else:
            metadata_list = [{'idx': i} for i in range(len(paragraphs))]
        
        # æ„å»ºå®Œæ•´ metadata
        full_metadata = {
            'paragraphs': paragraphs,
            'metadata': metadata_list
        }
        
        logger.info(f"âœ… å‹ç¼©ç´¢å¼•åŠ è½½å®Œæˆ: {len(paragraphs)} æ®µè½")
        
        # å¯é€‰ï¼šè§£å‹ä¿å­˜åˆ°æœ¬åœ°ï¼ˆä¸‹æ¬¡åŠ è½½æ›´å¿«ï¼‰
        try:
            index_dir.mkdir(exist_ok=True, parents=True)
            np.save(index_dir / "embeddings.npy", embeddings)
            with open(index_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(full_metadata, f, ensure_ascii=False)
            logger.info(f"ğŸ’¾ å·²è§£å‹ä¿å­˜åˆ°: {index_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ è§£å‹ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä½¿ç”¨ï¼‰: {e}")
        
        return embeddings, paragraphs, metadata_list
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å‹ç¼©ç´¢å¼•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


if __name__ == "__main__":
    # æµ‹è¯•
    logging.basicConfig(level=logging.INFO)
    
    result = load_compressed_index(Path("data"))
    if result:
        embeddings, paragraphs, metadata = result
        print(f"\nâœ… åŠ è½½æˆåŠŸ!")
        print(f"  Embeddings: {embeddings.shape}")
        print(f"  Paragraphs: {len(paragraphs)}")
        print(f"  Metadata: {len(metadata)}")
        print(f"\n  ç¬¬ä¸€æ®µç¤ºä¾‹: {paragraphs[0][:100]}...")
    else:
        print("\nâŒ åŠ è½½å¤±è´¥")
