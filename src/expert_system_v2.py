#!/usr/bin/env python3
"""
ä¸“å®¶ç³»ç»Ÿ V2 å®Œæ•´ç‰ˆ - è½»é‡æ–¹æ¡ˆ
æ•´åˆï¼šæ–‡æœ¬å¤„ç† + è½»é‡æ£€ç´¢ + ä¸“å®¶AI
"""

import json
from pathlib import Path
from typing import List, Dict
import logging

from lightweight_retriever import LightweightRetriever
from expert_ai_v2 import ExpertAIV2

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExpertSystemV2:
    """
    ä¸“å®¶ç³»ç»Ÿ V2ï¼ˆè½»é‡å®Œæ•´ç‰ˆï¼‰
    """
    
    def __init__(self, data_dir: str = "data", api_key: str = None):
        self.data_dir = Path(data_dir)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.retriever = None
        self.ai = None
        
        # åŠ è½½
        self._init_retriever()
        self._init_ai(api_key)
    
    def _init_retriever(self):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        logger.info("ğŸ“‚ åˆå§‹åŒ–æ£€ç´¢å™¨...")
        
        index_dir = self.data_dir / "semantic_index_light"
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
        if not (index_dir / "tfidf_matrix.npz").exists():
            logger.info("ğŸ“¦ ç´¢å¼•ä¸å­˜åœ¨ï¼Œå¼€å§‹æ„å»º...")
            self._build_index()
        
        # åŠ è½½ç´¢å¼•
        self.retriever = LightweightRetriever()
        self.retriever.load_index(index_dir)
        
        logger.info("âœ… æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _build_index(self):
        """æ„å»ºç´¢å¼•"""
        from text_processor_v2 import TextProcessorV2
        
        # æ£€æŸ¥å¤„ç†åçš„æ•°æ®æ˜¯å¦å­˜åœ¨
        para_file = self.data_dir / "processed_v2" / "paragraphs_v2.json"
        
        if not para_file.exists():
            logger.info("ğŸ“¦ å¤„ç†åŸå§‹æ•°æ®...")
            processor = TextProcessorV2()
            processor.process_novel(
                self.data_dir / "é›ªä¸­æ‚åˆ€è¡Œ.txt",
                self.data_dir / "processed_v2"
            )
        
        # åŠ è½½æ®µè½å¹¶æ„å»ºç´¢å¼•
        logger.info("ğŸ”¨ æ„å»ºè¯­ä¹‰ç´¢å¼•...")
        with open(para_file, 'r', encoding='utf-8') as f:
            paragraphs = json.load(f)
        
        retriever = LightweightRetriever()
        retriever.build_index(paragraphs, self.data_dir / "semantic_index_light")
    
    def _init_ai(self, api_key: str = None):
        """åˆå§‹åŒ–AI"""
        logger.info("ğŸ¤– åˆå§‹åŒ–ä¸“å®¶AI...")
        
        self.ai = ExpertAIV2(
            api_key=api_key,
            knowledge_base_path=self.data_dir
        )
        
        logger.info("âœ… AIåˆå§‹åŒ–å®Œæˆ")
    
    def retrieve(self, query: str, top_k: int = 5) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³æ®µè½"""
        return self.retriever.search(query, top_k=top_k)
    
    def get_context(self, query: str, top_k: int = 5) -> str:
        """è·å–å¢å¼ºä¸Šä¸‹æ–‡"""
        # æ£€ç´¢æ®µè½
        results = self.retrieve(query, top_k=top_k)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        
        # 1. ç›¸å…³åŸæ–‡æ®µè½
        context_parts.append("ã€ç›¸å…³åŸæ–‡ã€‘")
        for i, r in enumerate(results, 1):
            context_parts.append(f"\næ®µè½{i} [{r['chapter']}] (ç›¸å…³åº¦: {r['similarity']:.3f}):")
            context_parts.append(r['content'][:400])
        
        # 2. çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼ˆå¦‚æœAIå·²åŠ è½½ï¼‰
        if self.ai and self.ai.knowledge_base:
            # æå–æŸ¥è¯¢ä¸­çš„äººç‰©
            mentioned_chars = []
            for char in self.ai.knowledge_base.get('character_timeline', {}).keys():
                if char in query:
                    mentioned_chars.append(char)
            
            if mentioned_chars:
                context_parts.append("\n\nã€äººç‰©èƒŒæ™¯ã€‘")
                for char in mentioned_chars[:2]:
                    timeline = self.ai.knowledge_base.get('character_timeline', {}).get(char, [])
                    if timeline:
                        relevant = [
                            e for e in timeline 
                            if any(kw in e.get('event', '') for kw in query.split()[:3])
                        ][:2]
                        if relevant:
                            context_parts.append(f"\n{char}:")
                            for e in relevant:
                                context_parts.append(f"  - {e['chapter']}: {e['event'][:60]}...")
        
        return "\n".join(context_parts)
    
    def answer(self, query: str, temperature: float = 0.7) -> Dict:
        """ç”Ÿæˆä¸“å®¶çº§å›ç­”"""
        logger.info(f"ğŸ¤– å¤„ç†é—®é¢˜: {query[:50]}...")
        
        # è·å–ä¸Šä¸‹æ–‡
        context = self.get_context(query)
        
        # æ„å»ºæç¤º
        system_prompt = self.ai.build_system_prompt()
        user_prompt = f"""å…³äºã€Šé›ªä¸­æ‚åˆ€è¡Œã€‹çš„æ·±åº¦é—®é¢˜ï¼š

{query}

ä»¥ä¸‹æ˜¯æˆ‘ä¸ºä½ æ•´ç†çš„èƒŒæ™¯ä¿¡æ¯ï¼ˆåŒ…æ‹¬ç›¸å…³åŸæ–‡å’Œäººç‰©èƒŒæ™¯ï¼‰ï¼š

{context}

è¯·ä»¥æ–‡å­¦è¯„è®ºå®¶+ç²¾è¯»è€…çš„èº«ä»½ï¼Œç”¨ä¸‰æ®µå¼ç»“æ„ï¼ˆäº‹å®å±‚â†’åˆ†æå±‚â†’å‡åå±‚ï¼‰å›ç­”è¿™ä¸ªé—®é¢˜ã€‚æ·±å…¥åˆ†æï¼Œä¸è¦æ³›æ³›è€Œè°ˆã€‚"""
        
        # è°ƒç”¨API
        try:
            response = self.ai.client.chat.completions.create(
                model=self.ai.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=2500,
                stream=False
            )
            
            return {
                "success": True,
                "answer": response.choices[0].message.content,
                "query": query,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
        except Exception as e:
            logger.error(f"âŒ API é”™è¯¯: {e}")
            return {
                "success": False,
                "error": str(e),
                "query": query
            }


if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯• Expert System V2")
    print("="*60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = ExpertSystemV2(
        data_dir="data",
        api_key="sk-cdebe0fafcf9406d962e3e09a0404e4b"
    )
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¾å‡¤å¹´ä¸ºä»€ä¹ˆè¦æ€éŸ©è²‚å¯ºï¼Ÿ",
        "ç‹ä»™èŠä¸ºä»€ä¹ˆè‡ªç§°å¤©ä¸‹ç¬¬äºŒï¼Ÿ",
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"â“ {query}")
        print(f"{'='*60}")
        
        result = system.answer(query)
        
        if result['success']:
            print(f"\nğŸ’¬ å›ç­”:")
            print(result['answer'])
            print(f"\nğŸ’° Token: {result['usage']['total_tokens']}")
        else:
            print(f"âŒ é”™è¯¯: {result['error']}")
