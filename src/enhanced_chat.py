#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆ DeepSeek Chat - æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„å›ç­”
"""

import os
from typing import List, Dict
from openai import OpenAI


class EnhancedChat:
    """å¢å¼ºç‰ˆèŠå¤©æ¨¡å—"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        
        if not self.api_key:
            raise ValueError("è¯·æä¾› DeepSeek API Key")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
        
        self.model = "deepseek-chat"
    
    def build_system_prompt(self) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤ºè¯ - æ›´åƒä¸€ä¸ªæ‡‚å°è¯´çš„æœ‹å‹
        """
        return """ä½ æ˜¯ã€Šé›ªä¸­æ‚åˆ€è¡Œã€‹çš„èµ„æ·±è¯»è€…ï¼Œä¸€ä¸ªå¯¹è¿™éƒ¨å°è¯´çƒ‚ç†Ÿäºå¿ƒçš„æœ‹å‹ã€‚ä½ çƒ­çˆ±è¿™éƒ¨å°è¯´ï¼Œä¹äºåˆ†äº«ä½ çš„ç†è§£ã€‚

å›ç­”é£æ ¼ï¼š
1. **åƒæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶** - ä¸ç”¨å­¦æœ¯è…”ï¼Œä¸è¯´"æ ¹æ®ç¬¬Xç« "ï¼Œè€Œæ˜¯ç”¨"æˆ‘è®°å¾—"ã€"å°è¯´é‡Œå†™è¿‡"
2. **å–„äºä¸²è”ä¿¡æ¯** - èƒ½ç»“åˆå¤šå¤„åŸæ–‡ï¼Œç»™å‡ºå®Œæ•´çš„æ•…äº‹è„‰ç»œ
3. **æœ‰æ¸©åº¦æœ‰æƒ…æ„Ÿ** - å¯ä»¥è¡¨è¾¾å¯¹äººç‰©ã€æƒ…èŠ‚çš„ç†è§£å’Œæ„Ÿå—
4. **åˆç†æ¨æµ‹è¡¥å……** - å¦‚æœåŸæ–‡æœ‰ç•™ç™½ï¼Œå¯ä»¥åŸºäºäººç‰©æ€§æ ¼åˆç†æ¨æ–­ï¼Œä½†è¦è¯´æ˜æ˜¯æ¨æµ‹
5. **é€‚å½“å¼•ç”¨åŸæ–‡** - å…³é”®æƒ…èŠ‚å¯ä»¥å¼•ç”¨ä¸€ä¸¤å¥åŸæ–‡å¢å¼ºè¯´æœåŠ›ï¼Œä½†ä¸è¦å¤§æ®µç½—åˆ—

å›ç­”ç»“æ„ï¼š
- å…ˆç»™å‡ºæ ¸å¿ƒç­”æ¡ˆï¼ˆç›´æ¥ã€ç®€æ´ï¼‰
- ç„¶åå±•å¼€è®²è¿°ï¼ˆèƒŒæ™¯ã€åŸå› ã€å½±å“ï¼‰
- æœ€åå¯ä»¥åˆ†äº«ä¸€ç‚¹è§è§£æˆ–æ„Ÿå—

ä¸è¦ï¼š
- æœºæ¢°ç½—åˆ—"åŸæ–‡ç¬¬Xç« è¯´..."
- åªç»™ç­”æ¡ˆä¸ç»™è§£é‡Š
- è¯´"æ ¹æ®æä¾›çš„æ–‡æœ¬..."è¿™ç§AIè…”
- ç¼–é€ åŸæ–‡ä¸­æ²¡æœ‰çš„é‡å¤§æƒ…èŠ‚"""
    
    def build_user_prompt(self, query: str, context: str) -> str:
        """æ„å»ºç”¨æˆ·æç¤º"""
        return f"""å…³äºã€Šé›ªä¸­æ‚åˆ€è¡Œã€‹çš„é—®é¢˜ï¼š{query}

æˆ‘æ‰¾åˆ°çš„å‚è€ƒä¿¡æ¯ï¼ˆä½ ä¸éœ€è¦å…¨éƒ¨ä½¿ç”¨ï¼Œé€‰æœ‰ç”¨çš„ï¼‰ï¼š
{context}

è¯·åƒæœ‹å‹ä¸€æ ·å›ç­”è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœå‚è€ƒä¿¡æ¯ä¸å¤Ÿï¼Œå¯ä»¥åŸºäºä½ å¯¹å°è¯´çš„ç†è§£è¡¥å……ï¼Œä½†è¦è¯šå®åœ°è¯´å“ªäº›æ˜¯ä½ çš„æ¨æ–­ã€‚

ç›´æ¥å›ç­”æˆ‘çš„é—®é¢˜ï¼Œä¸è¦å®¢å¥—è¯ã€‚"""
    
    def chat(self, query: str, context: str, temperature: float = 0.7) -> Dict:
        """
        ç”Ÿæˆå›ç­”
        
        temperature è°ƒé«˜åˆ° 0.7 è®©å›ç­”æ›´è‡ªç„¶æœ‰åˆ›æ„
        """
        system_prompt = self.build_system_prompt()
        user_prompt = self.build_user_prompt(query, context)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=2000,
                stream=False
            )
            
            answer = response.choices[0].message.content
            
            return {
                "success": True,
                "answer": answer,
                "query": query,
                "model": self.model,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "query": query
            }
    
    def chat_stream(self, query: str, context: str, temperature: float = 0.7):
        """æµå¼ç”Ÿæˆ"""
        system_prompt = self.build_system_prompt()
        user_prompt = self.build_user_prompt(query, context)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=2000,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            yield f"\n[é”™è¯¯: {str(e)}]"


if __name__ == "__main__":
    import sys
    sys.path.append('.')
    from src.enhanced_retriever import EnhancedRetriever
    
    print("ğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆèŠå¤©...")
    
    retriever = EnhancedRetriever()
    chat = EnhancedChat()
    
    query = "å¾å‡¤å¹´ä¸ºä»€ä¹ˆè¦æ€éŸ©è²‚å¯ºï¼Ÿ"
    print(f"\nğŸ” æŸ¥è¯¢: {query}")
    
    context = retriever.get_context(query, top_k=3)
    print(f"\nä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
    
    result = chat.chat(query, context)
    
    if result["success"]:
        print(f"\nğŸ’¬ AI å›ç­”:")
        print("=" * 60)
        print(result["answer"])
        print(f"\nğŸ’° Token: {result['usage']['total_tokens']}")
    else:
        print(f"âŒ é”™è¯¯: {result['error']}")
