#!/usr/bin/env python3
"""
ç« èŠ‚æ‘˜è¦ç”Ÿæˆå™¨ - æå–æ¯ç« æ ¸å¿ƒå†…å®¹
"""

import json
import re
from pathlib import Path
from typing import Dict, List


class ChapterSummarizer:
    """ç”Ÿæˆç« èŠ‚æ‘˜è¦"""
    
    def __init__(self):
        self.chapters = []  # ç« èŠ‚åˆ—è¡¨
        
    def parse_chapters(self, text: str) -> List[Dict]:
        """è§£æç« èŠ‚ç»“æ„"""
        print("ğŸ“š æ­£åœ¨è§£æç« èŠ‚ç»“æ„...")
        
        # åŒ¹é…ç« èŠ‚æ ‡é¢˜ï¼ˆå¤šç§æ ¼å¼ï¼‰
        chapter_patterns = [
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶\d]+ç« \s+.+',  # ç¬¬ä¸€ç«  æ ‡é¢˜
            r'ç¬¬[\d]+ç« \s+.+',  # ç¬¬1ç«  æ ‡é¢˜
        ]
        
        chapters = []
        lines = text.split('\n')
        current_chapter = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
            is_chapter = False
            for pattern in chapter_patterns:
                if re.match(pattern, line):
                    # ä¿å­˜ä¸Šä¸€ç« 
                    if current_chapter:
                        chapters.append({
                            'title': current_chapter,
                            'content': '\n'.join(current_content),
                            'word_count': len(''.join(current_content))
                        })
                    
                    current_chapter = line
                    current_content = []
                    is_chapter = True
                    break
            
            if not is_chapter and current_chapter:
                current_content.append(line)
        
        # ä¿å­˜æœ€åä¸€ç« 
        if current_chapter and current_content:
            chapters.append({
                'title': current_chapter,
                'content': '\n'.join(current_content),
                'word_count': len(''.join(current_content))
            })
        
        self.chapters = chapters
        print(f"âœ… è§£æå®Œæˆï¼Œå…± {len(chapters)} ç« ")
        return chapters
    
    def extract_key_events(self, chapter_content: str) -> List[str]:
        """æå–ç« èŠ‚å…³é”®äº‹ä»¶"""
        events = []
        
        # æå–å…³é”®å¥ï¼ˆåŒ…å«äººç‰©åŠ¨ä½œçš„å¥å­ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', chapter_content)
        
        # å…³é”®è¯æƒé‡
        action_keywords = ['æ€', 'æˆ˜', 'æ–—', 'é‡', 'è§', 'è¯´', 'é—®', 'ç­”', 'èµ°', 'æ¥', 'å»', 'æ­»', 'ä¼¤', 'èƒœ', 'è´¥']
        
        for sent in sentences:
            sent = sent.strip()
            if len(sent) < 10 or len(sent) > 100:
                continue
            
            # åŒ…å«ä¸»è¦äººç‰©çš„å¥å­æ›´å¯èƒ½æ˜¯å…³é”®äº‹ä»¶
            main_chars = ['å¾å‡¤å¹´', 'å¾éª', 'å§œæ³¥', 'ææ·³ç½¡', 'é‚“å¤ªé˜¿', 'ç‹ä»™èŠ', 'æ‹“è·‹è©è¨']
            has_main_char = any(char in sent for char in main_chars)
            
            # åŒ…å«åŠ¨ä½œå…³é”®è¯
            has_action = any(kw in sent for kw in action_keywords)
            
            if has_main_char and has_action:
                events.append(sent)
        
        # è¿”å›å‰5ä¸ªå…³é”®äº‹ä»¶
        return events[:5]
    
    def extract_characters_in_chapter(self, chapter_content: str) -> List[str]:
        """æå–ç« èŠ‚ä¸­å‡ºç°çš„äººç‰©"""
        main_chars = ['å¾å‡¤å¹´', 'å¾éª', 'å§œæ³¥', 'å—å®«ä»†å°„', 'ææ·³ç½¡', 'é‚“å¤ªé˜¿', 
                     'ç‹ä»™èŠ', 'æ‹“è·‹è©è¨', 'æ›¹é•¿å¿', 'é™ˆèŠè±¹', 'è¤šç¦„å±±', 'è¢å·¦å®—']
        
        found = []
        for char in main_chars:
            if char in chapter_content:
                found.append(char)
        
        return found
    
    def generate_summary(self, chapter: Dict) -> Dict:
        """ç”Ÿæˆå•ç« æ‘˜è¦"""
        content = chapter['content']
        
        # æå–å…³é”®äº‹ä»¶
        key_events = self.extract_key_events(content)
        
        # æå–äººç‰©
        characters = self.extract_characters_in_chapter(content)
        
        # æå–åœ°ç‚¹ï¼ˆç®€å•åŒ¹é…ï¼‰
        locations = []
        location_keywords = ['åŒ—å‡‰', 'ç¦»é˜³', 'å¤ªå®‰åŸ', 'æ­¦å¸åŸ', 'æ¸…å‡‰å±±', 'åŒ—è½']
        for loc in location_keywords:
            if loc in content:
                locations.append(loc)
        
        return {
            'title': chapter['title'],
            'word_count': chapter['word_count'],
            'key_events': key_events,
            'characters': characters,
            'locations': list(set(locations))
        }
    
    def generate_all_summaries(self) -> List[Dict]:
        """ç”Ÿæˆæ‰€æœ‰ç« èŠ‚æ‘˜è¦"""
        print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆ {len(self.chapters)} ç« çš„æ‘˜è¦...")
        
        summaries = []
        for i, chapter in enumerate(self.chapters):
            if (i + 1) % 50 == 0:
                print(f"  è¿›åº¦: {i+1}/{len(self.chapters)}")
            
            summary = self.generate_summary(chapter)
            summaries.append(summary)
        
        print(f"âœ… ç« èŠ‚æ‘˜è¦ç”Ÿæˆå®Œæˆ")
        return summaries
    
    def save(self, summaries: List[Dict], output_path: Path):
        """ä¿å­˜æ‘˜è¦"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summaries, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ç« èŠ‚æ‘˜è¦å·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    # æµ‹è¯•
    data_dir = Path("data")
    
    # åŠ è½½å°è¯´
    print("ğŸ“– åŠ è½½å°è¯´...")
    with open(data_dir / "é›ªä¸­æ‚åˆ€è¡Œ.txt", 'r', encoding='utf-8') as f:
        text = f.read()
    
    # è§£æç« èŠ‚
    summarizer = ChapterSummarizer()
    chapters = summarizer.parse_chapters(text)
    
    # ç”Ÿæˆæ‘˜è¦
    summaries = summarizer.generate_all_summaries()
    
    # æ˜¾ç¤ºå‰3ç« ç¤ºä¾‹
    print("\nğŸ“‹ å‰3ç« æ‘˜è¦ç¤ºä¾‹:")
    for s in summaries[:3]:
        print(f"\n{s['title']}")
        print(f"  å­—æ•°: {s['word_count']}")
        print(f"  äººç‰©: {', '.join(s['characters'])}")
        print(f"  å…³é”®äº‹ä»¶: {s['key_events'][0] if s['key_events'] else 'æ— '}")
    
    # ä¿å­˜
    summarizer.save(summaries, data_dir / "chapter_summaries.json")
