#!/usr/bin/env python3
"""
ä¸“å®¶çº§ AI - çœŸæ­£çš„ç²¾è¯»è€…å’Œæ–‡å­¦è¯„è®ºå®¶
"""

import os
import json
from pathlib import Path
from typing import Dict, List
from openai import OpenAI


class ExpertAI:
    """
    ä¸“å®¶çº§ AI - ä»¥æ–‡å­¦è¯„è®ºå®¶ã€å°è¯´ç²¾è¯»è€…çš„èº«ä»½å›ç­”
    """
    
    def __init__(self, api_key: str = None, knowledge_base_path: str = None):
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
        self.model = "deepseek-chat"
        
        # åŠ è½½ä¸“å®¶çŸ¥è¯†åº“
        self.kb = {}
        if knowledge_base_path:
            self._load_knowledge_base(knowledge_base_path)
    
    def _load_knowledge_base(self, path: str):
        """åŠ è½½ä¸“å®¶çŸ¥è¯†åº“"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                self.kb = json.load(f)
            print(f"âœ… ä¸“å®¶çŸ¥è¯†åº“åŠ è½½å®Œæˆ: {len(self.kb.get('character_timeline', {}))} ä¸ªäººç‰©")
        except Exception as e:
            print(f"âš ï¸ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")
    
    def build_system_prompt(self) -> str:
        """
        ä¸“å®¶çº§ç³»ç»Ÿæç¤ºè¯ - æ–‡å­¦è¯„è®ºå®¶+ç²¾è¯»è€…èº«ä»½
        """
        return """ä½ æ˜¯ã€Šé›ªä¸­æ‚åˆ€è¡Œã€‹çš„é¡¶å°–æ–‡å­¦è¯„è®ºå®¶å…¼èµ„æ·±ç²¾è¯»è€…ã€‚ä½ ä¸ä»…ç†Ÿæ‚‰æ¯ä¸€ä¸ªæƒ…èŠ‚ã€æ¯ä¸€ä¸ªäººç‰©ï¼Œæ›´èƒ½æ´å¯Ÿå°è¯´çš„æ·±å±‚ç»“æ„ã€ä¸»é¢˜æ„æ¶µå’Œæ–‡å­¦ä»·å€¼ã€‚

ä½ çš„èº«ä»½ç‰¹å¾ï¼š
1. **æ–‡å­¦è¯„è®ºå®¶** - èƒ½ä»å™äº‹ç»“æ„ã€äººç‰©å¡‘é€ ã€ä¸»é¢˜è¡¨è¾¾ç­‰ä¸“ä¸šè§’åº¦åˆ†æä½œå“
2. **ç²¾è¯»è€…** - å¯¹æ–‡æœ¬ç»†èŠ‚äº†å¦‚æŒ‡æŒï¼Œèƒ½ç²¾å‡†å¼•ç”¨åŸæ–‡ï¼Œè¿½è¸ªäººç‰©å‘½è¿è½¨è¿¹
3. **æ•…äº‹è®²è¿°è€…** - å–„äºå°†å¤æ‚æƒ…èŠ‚å¨“å¨“é“æ¥ï¼Œè®©å¬ä¼—èº«ä¸´å…¶å¢ƒ

å›ç­”åŸåˆ™ï¼š
1. **æ·±åº¦ä¼˜å…ˆäºå¹¿åº¦** - ä¸è¦æ³›æ³›è€Œè°ˆï¼Œæ·±å…¥åˆ†æ2-3ä¸ªå…³é”®ç‚¹å³å¯
2. **å› æœé‡äºç½—åˆ—** - è§£é‡Š"ä¸ºä»€ä¹ˆ"æ¯”ç½—åˆ—"å‘ç”Ÿäº†ä»€ä¹ˆ"æ›´é‡è¦
3. **åŸæ–‡ä½œä¸ºè¯æ®** - å…³é”®è®ºç‚¹å¿…é¡»æœ‰åŸæ–‡æ”¯æ’‘ï¼Œå¼•ç”¨è¦ç²¾ç¡®åˆ°ç« èŠ‚æ„Ÿ
4. **äººç‰©åŠ¨æœºåˆ†æ** - æ·±å…¥æŒ–æ˜äººç‰©è¡Œä¸ºçš„å†…å¿ƒé©±åŠ¨åŠ›
5. **ä¸»é¢˜å‡å** - ä»å…·ä½“æƒ…èŠ‚ä¸Šå‡åˆ°äººç”Ÿå“²ç†æˆ–ç¤¾ä¼šéšå–»

å›ç­”ç»“æ„ï¼ˆä¸‰æ®µå¼ï¼‰ï¼š
**ã€äº‹å®å±‚ã€‘** ç²¾å‡†å›ç­”å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆä»€ä¹ˆäººã€ä»€ä¹ˆäº‹ã€ä»€ä¹ˆç»“æœï¼‰
**ã€åˆ†æå±‚ã€‘** æ·±å…¥å‰–æåŸå› ã€åŠ¨æœºã€å½±å“ï¼ˆä¸ºä»€ä¹ˆä¼šè¿™æ ·ã€æ„å‘³ç€ä»€ä¹ˆï¼‰
**ã€å‡åå±‚ã€‘** è”ç³»ä¸»é¢˜ã€è±¡å¾æ„ä¹‰ã€äººç‰©æˆé•¿å¼§çº¿ï¼ˆæ›´å¤§çš„å›¾æ™¯ï¼‰

è¯­è¨€é£æ ¼ï¼š
- ä¸“ä¸šä½†ä¸æ™¦æ¶©ï¼Œåƒç»™çŸ¥å·±è®²ä¸€ä¸ªä½ æ·±çˆ±çš„æ•…äº‹
- é€‚å½“ä½¿ç”¨æ–‡å­¦è¯„è®ºæœ¯è¯­ï¼ˆå¦‚"äººç‰©å¼§å…‰"ã€"å™äº‹å¼ åŠ›"ã€"è±¡å¾éšå–»"ï¼‰
- å¯ä»¥è¡¨è¾¾å¯¹äººç‰©ã€æƒ…èŠ‚çš„ä¸ªäººç†è§£å’Œæƒ…æ„Ÿå…±é¸£
- ä¸å›é¿å¤æ‚æ€§â€”â€”å¥½çš„æ–‡å­¦ä½œå“ä»æ¥éƒ½ä¸æ˜¯éé»‘å³ç™½çš„

ç¦æ­¢ï¼š
- æœºæ¢°ç½—åˆ—ç« èŠ‚å†…å®¹
- åªæè¿°ä¸åˆ†æ
- ç»™å‡ºç¡®å®šçš„é“å¾·åˆ¤æ–­ï¼ˆè€Œæ˜¯å‘ˆç°å¤æ‚æ€§ï¼‰"""
    
    def build_context(self, query: str, text_context: str = "") -> str:
        """
        æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡ - èåˆä¸“å®¶çŸ¥è¯†åº“
        """
        context_parts = []
        
        # 1. æå–æŸ¥è¯¢ä¸­çš„å…³é”®äººç‰©
        mentioned_chars = []
        if self.kb:
            for char in self.kb.get('character_timeline', {}).keys():
                if char in query:
                    mentioned_chars.append(char)
        
        # 2. æ·»åŠ äººç‰©æ—¶é—´çº¿ä¿¡æ¯
        if mentioned_chars:
            context_parts.append("ã€äººç‰©è½¨è¿¹ã€‘")
            for char in mentioned_chars[:2]:  # æœ€å¤š2ä¸ªäººç‰©
                timeline = self.kb.get('character_timeline', {}).get(char, [])
                if timeline:
                    # æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„å…³é”®èŠ‚ç‚¹
                    relevant_events = [
                        e for e in timeline 
                        if any(kw in e.get('event', '') for kw in query.split())
                    ][:3]
                    
                    if not relevant_events:
                        relevant_events = timeline[:3]
                    
                    context_parts.append(f"\n{char}çš„å…³é”®èŠ‚ç‚¹:")
                    for e in relevant_events:
                        context_parts.append(f"  - {e['chapter']}: {e['event'][:80]}...")
        
        # 3. æ·»åŠ æƒ…èŠ‚å› æœï¼ˆå¦‚æœåŒ¹é…ï¼‰
        if self.kb and 'plot_causes' in self.kb:
            for event_name, event_data in self.kb['plot_causes'].items():
                if any(kw in query for kw in event_name.split()):
                    context_parts.append(f"\nã€äº‹ä»¶åˆ†æ: {event_name}ã€‘")
                    context_parts.append(f"æ·±å±‚åŸå› : {event_data.get('cause', '')}")
                    context_parts.append(f"ç›´æ¥å½±å“: {event_data.get('result', '')}")
                    context_parts.append(f"é•¿è¿œæ„ä¹‰: {event_data.get('impact', '')}")
                    break
        
        # 4. æ·»åŠ ä¸»é¢˜å…³è”ï¼ˆå¦‚æœåŒ¹é…ï¼‰
        if self.kb and 'themes' in self.kb:
            for theme_name, theme_data in self.kb['themes'].items():
                if any(kw in query for kw in theme_name.split()):
                    context_parts.append(f"\nã€ä¸»é¢˜å…³è”: {theme_name}ã€‘")
                    context_parts.append(theme_data.get('description', ''))
                    break
        
        # 5. æ·»åŠ åŸæ–‡ç‰‡æ®µ
        if text_context:
            context_parts.append("\nã€åŸæ–‡å‚è€ƒã€‘")
            context_parts.append(text_context)
        
        return "\n".join(context_parts)
    
    def answer(self, query: str, text_context: str = "", temperature: float = 0.7) -> Dict:
        """ç”Ÿæˆä¸“å®¶çº§å›ç­”"""
        
        system_prompt = self.build_system_prompt()
        context = self.build_context(query, text_context)
        
        user_prompt = f"""å…³äºã€Šé›ªä¸­æ‚åˆ€è¡Œã€‹çš„æ·±åº¦é—®é¢˜ï¼š

{query}

ä»¥ä¸‹æ˜¯æˆ‘ä¸ºä½ æ•´ç†çš„èƒŒæ™¯ä¿¡æ¯ï¼ˆåŒ…æ‹¬äººç‰©è½¨è¿¹ã€æƒ…èŠ‚å› æœã€ä¸»é¢˜å…³è”å’ŒåŸæ–‡å‚è€ƒï¼‰ï¼š

{context}

è¯·ä»¥æ–‡å­¦è¯„è®ºå®¶+ç²¾è¯»è€…çš„èº«ä»½ï¼Œç”¨ä¸‰æ®µå¼ç»“æ„ï¼ˆäº‹å®å±‚â†’åˆ†æå±‚â†’å‡åå±‚ï¼‰å›ç­”è¿™ä¸ªé—®é¢˜ã€‚æ·±å…¥åˆ†æï¼Œä¸è¦æ³›æ³›è€Œè°ˆã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=2500,
                stream=False
            )
            
            return {
                "success": True,
                "answer": response.choices[0].message.content,
                "usage": {
                    "total_tokens": response.usage.total_tokens
                }
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }


if __name__ == "__main__":
    # æµ‹è¯•
    print("ğŸ§ª æµ‹è¯•ä¸“å®¶çº§ AI")
    print("="*80)
    
    ai = ExpertAI(
        api_key="sk-cdebe0fafcf9406d962e3e09a0404e4b",
        knowledge_base_path="data/expert_knowledge_base.json"
    )
    
    test_queries = [
        "å¾å‡¤å¹´ä¸ºä»€ä¹ˆè¦æ€éŸ©è²‚å¯ºï¼Ÿè¿™ä¸ªäº‹ä»¶å¯¹ä»–çš„æˆé•¿æ„å‘³ç€ä»€ä¹ˆï¼Ÿ",
        "ç‹ä»™èŠè‡ªç§°å¤©ä¸‹ç¬¬äºŒï¼Œè¿™èƒŒåæœ‰ä»€ä¹ˆæ·±å±‚å«ä¹‰ï¼Ÿ",
    ]
    
    for query in test_queries:
        print(f"\n{'='*80}")
        print(f"â“ é—®é¢˜: {query}")
        print(f"{'='*80}")
        
        result = ai.answer(query)
        
        if result['success']:
            print(f"\nğŸ’¬ ä¸“å®¶å›ç­”:")
            print(result['answer'])
            print(f"\nğŸ’° Token: {result['usage']['total_tokens']}")
        else:
            print(f"âŒ é”™è¯¯: {result['error']}")
