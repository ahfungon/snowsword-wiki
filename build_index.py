#!/usr/bin/env python3
"""
æ„å»ºæ‰€æœ‰å¢å¼ºç´¢å¼•
"""

import sys
from pathlib import Path

sys.path.append('.')

from src.indexer import TextIndexer
from src.knowledge_graph import KnowledgeGraph
from src.chapter_summarizer import ChapterSummarizer
import json
import gzip


def build_all():
    """æ„å»ºæ‰€æœ‰ç´¢å¼•"""
    data_dir = Path("data")
    
    # 1. æ£€æŸ¥å°è¯´æ–‡æœ¬
    text_file = data_dir / "é›ªä¸­æ‚åˆ€è¡Œ.txt"
    if not text_file.exists():
        print("âŒ æ‰¾ä¸åˆ°å°è¯´æ–‡æœ¬æ–‡ä»¶")
        return
    
    print("ğŸ“– åŠ è½½å°è¯´æ–‡æœ¬...")
    with open(text_file, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print(f"   æ–‡æœ¬é•¿åº¦: {len(text):,} å­—ç¬¦")
    
    # 2. æ„å»ºæ–‡æœ¬å—ç´¢å¼•
    chunks_path = data_dir / "chunks.json"
    if not chunks_path.exists():
        print("\nğŸ“ æ„å»ºæ–‡æœ¬å—ç´¢å¼•...")
        indexer = TextIndexer(chunk_size=800, overlap=100)
        chunks = indexer.create_chunks(text)
        
        with open(chunks_path, 'w', encoding='utf-8') as f:
            json.dump(chunks, f, ensure_ascii=False)
        print(f"   âœ“ ç”Ÿæˆäº† {len(chunks)} ä¸ªæ–‡æœ¬å—")
    else:
        print(f"\nğŸ“¦ æ–‡æœ¬å—ç´¢å¼•å·²å­˜åœ¨")
        with open(chunks_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
    
    # 3. å‹ç¼©åˆ†å—ï¼ˆ30MBæ¯ä»½ï¼‰
    print("\nğŸ—œï¸  å‹ç¼©åˆ†å—æ–‡ä»¶...")
    import subprocess
    
    # æ¸…ç†æ—§æ–‡ä»¶
    for f in data_dir.glob("chunks_small_*.gz"):
        f.unlink()
    
    # åˆ†å‰²
    subprocess.run(f"cd {data_dir} && split -b 30m chunks.json chunks_small_", shell=True)
    
    # å‹ç¼©
    for part in data_dir.glob("chunks_small_*"):
        if not str(part).endswith('.gz'):
            subprocess.run(f"gzip -9 {part}", shell=True)
            print(f"   âœ“ {part.name}.gz")
    
    # 4. æ„å»ºçŸ¥è¯†å›¾è°±
    kg_path = data_dir / "knowledge_graph.json"
    if not kg_path.exists():
        print("\nğŸ•¸ï¸  æ„å»ºçŸ¥è¯†å›¾è°±...")
        graph = KnowledgeGraph()
        graph.build_from_text(text[:100000])  # å…ˆç”¨å‰10ä¸‡å­—
        graph.save(kg_path)
    else:
        print(f"\nğŸ“¦ çŸ¥è¯†å›¾è°±å·²å­˜åœ¨")
    
    # 5. æ„å»ºç« èŠ‚æ‘˜è¦
    summary_path = data_dir / "chapter_summaries.json"
    if not summary_path.exists():
        print("\nğŸ“š æ„å»ºç« èŠ‚æ‘˜è¦...")
        summarizer = ChapterSummarizer()
        chapters = summarizer.parse_chapters(text)
        summaries = summarizer.generate_all_summaries()
        summarizer.save(summaries, summary_path)
    else:
        print(f"\nğŸ“¦ ç« èŠ‚æ‘˜è¦å·²å­˜åœ¨")
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰ç´¢å¼•æ„å»ºå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    build_all()
